{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18656a82",
   "metadata": {},
   "source": [
    "# install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf68cfa",
   "metadata": {},
   "source": [
    "## NOTE: This environment has been installed basic libraries like as torch, jupyter, pandas, numpy, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a85dc792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opendatasets transformers pandas-profiling -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec91fdf",
   "metadata": {},
   "source": [
    "# prepare data files and authorize kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d649d81",
   "metadata": {},
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download('https://www.kaggle.com/c/nlp-getting-started', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb19e0",
   "metadata": {},
   "source": [
    "!cp ./nlp-getting-started/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224fde0",
   "metadata": {},
   "source": [
    "# load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01abf8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       0\n",
       "1         2       0\n",
       "2         3       0\n",
       "3         9       0\n",
       "4        11       0\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       0\n",
       "3260  10868       0\n",
       "3261  10874       0\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sample_df = pd.read_csv('sample_submission.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bc209",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46eea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5f39d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df0395f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df['text'].values\n",
    "train_labels = train_df['target'].values\n",
    "test_sentences = test_df['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c22b1d",
   "metadata": {},
   "source": [
    "## show frequency of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a9fe51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  85.,  296.,  445.,  551.,  779.,  973.,  961., 1032., 2334.,\n",
       "         157.]),\n",
       " array([  7.,  22.,  37.,  52.,  67.,  82.,  97., 112., 127., 142., 157.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(sentence) for sentence in train_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76ce9972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 35., 111., 153., 218., 272., 408., 388., 386., 755., 537.]),\n",
       " array([  5. ,  19.6,  34.2,  48.8,  63.4,  78. ,  92.6, 107.2, 121.8,\n",
       "        136.4, 151. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sentence) for sentence in test_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d231dc",
   "metadata": {},
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7218e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(sentence) for sentence in np.concatenate([train_sentences, test_sentences], axis=0)])\n",
    "max_length = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36dcd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encode_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encode_dict['input_ids'])\n",
    "        attention_masks.append(encode_dict['attention_mask'])\n",
    "        \n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d92f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = encode_sentences(train_sentences, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88a1c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd5bbb",
   "metadata": {},
   "source": [
    "# set dataset and dataloader for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "35d26bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a518c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c58e23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.99)\n",
    "val_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c0f6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2675b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            sampler=SequentialSampler(val_dataset),\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5b79c",
   "metadata": {},
   "source": [
    "# set pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb7db420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b25794",
   "metadata": {},
   "source": [
    "# set optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f4d8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c0ca364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16932ec",
   "metadata": {},
   "source": [
    "# set learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ad3d9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0bc2139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "total_step = len(train_dataset) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "62ad5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89bded19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(preds_flat == labels_flat) / len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10d5c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc6958b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    40  of    471.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    471.    Elapsed: 0:00:05.\n",
      "  Batch   120  of    471.    Elapsed: 0:00:08.\n",
      "  Batch   160  of    471.    Elapsed: 0:00:10.\n",
      "  Batch   200  of    471.    Elapsed: 0:00:13.\n",
      "  Batch   240  of    471.    Elapsed: 0:00:15.\n",
      "  Batch   280  of    471.    Elapsed: 0:00:18.\n",
      "  Batch   320  of    471.    Elapsed: 0:00:20.\n",
      "  Batch   360  of    471.    Elapsed: 0:00:23.\n",
      "  Batch   400  of    471.    Elapsed: 0:00:25.\n",
      "  Batch   440  of    471.    Elapsed: 0:00:28.\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:00:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.40\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:00:30 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "previous_val_loss = 0\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        loss = output[0]\n",
    "        logits = output[1]\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)          \n",
    "    \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            output = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels)\n",
    "            loss = output[0]\n",
    "            logits = output[1]\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += get_accuracy(logits, label_ids)\n",
    "        \n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if epoch_i == 0:\n",
    "        previous_val_loss = avg_val_loss\n",
    "    else:\n",
    "        if previous_val_loss <= avg_val_loss:\n",
    "            break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "00721606",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks = encode_sentences(test_sentences, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0e9184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.tensor(np.ones(len(test_input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "806bc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "predict_dataloader = DataLoader(predict_data, sampler=SequentialSampler(predict_data), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb87ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in predict_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    b_input_ids, b_attention_masks, b_labels = batch    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_masks, token_type_ids=None)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    pred_flatten = np.argmax(logits,axis=1).flatten()\n",
    "\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    label_ids = label_ids.flatten()\n",
    "    \n",
    "    predictions.extend(pred_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731856f",
   "metadata": {},
   "source": [
    "# calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4dd08de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4781d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d21a9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443150475022985"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df[correct_df['target'].values == predictions].shape[0] / correct_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b074afd",
   "metadata": {},
   "source": [
    "# save submission file and submit predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b24378",
   "metadata": {},
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa92b96",
   "metadata": {},
   "source": [
    "with open('submission.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'target'])\n",
    "    for idx, target in zip(test_df['id'].values, predictions):\n",
    "        writer.writerow([idx, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba43ca4",
   "metadata": {},
   "source": [
    "#!kaggle competitions submit -c nlp-getting-started -f submission.csv -m \"My third try\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f48cb",
   "metadata": {},
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d80f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478a637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c34153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644e696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7c19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
