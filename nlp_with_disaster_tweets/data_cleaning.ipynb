{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18656a82",
   "metadata": {},
   "source": [
    "# install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf68cfa",
   "metadata": {},
   "source": [
    "## NOTE: This environment has been installed basic libraries like as torch, jupyter, pandas, numpy, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85dc792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opendatasets transformers pandas-profiling -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224fde0",
   "metadata": {},
   "source": [
    "# load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01abf8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       0\n",
       "1         2       0\n",
       "2         3       0\n",
       "3         9       0\n",
       "4        11       0\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       0\n",
       "3260  10868       0\n",
       "3261  10874       0\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sample_df = pd.read_csv('sample_submission.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b817ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1096e22d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bc209",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46eea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f39d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0395f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df['text'].values\n",
    "train_labels = train_df['target'].values\n",
    "test_sentences = test_df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af71acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (3.6.5)\n",
      "Requirement already satisfied: joblib in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from nltk) (2021.10.8)\n",
      "Requirement already satisfied: click in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from click->nltk) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42aa381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charles/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/charles/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/charles/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7649f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_sentences(text, invalid_pattern='[^a-zA-Z0-9]|http://t.co/[0-9a-zA-Z]+'):\n",
    "    cleaned_text = re.sub(invalid_pattern, ' ', text.lower())\n",
    "    \n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9713b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [cleaning_sentences(sentence) for sentence in train_sentences]\n",
    "test_sentences = [cleaning_sentences(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c22b1d",
   "metadata": {},
   "source": [
    "## show frequency of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a9fe51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 157.,  557.,  992., 1220., 1383., 1522., 1088.,  545.,  131.,\n",
       "          18.]),\n",
       " array([  3. ,  16.4,  29.8,  43.2,  56.6,  70. ,  83.4,  96.8, 110.2,\n",
       "        123.6, 137. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(sentence) for sentence in train_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76ce9972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 44., 191., 333., 446., 555., 634., 573., 355., 121.,  11.]),\n",
       " array([  0. ,  13.1,  26.2,  39.3,  52.4,  65.5,  78.6,  91.7, 104.8,\n",
       "        117.9, 131. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sentence) for sentence in test_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d231dc",
   "metadata": {},
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7218e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(sentence) for sentence in np.concatenate([train_sentences, test_sentences], axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36dcd62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        encode_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encode_dict['input_ids'])\n",
    "        attention_masks.append(encode_dict['attention_mask'])\n",
    "        \n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d92f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks = encode_sentences(train_sentences, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88a1c1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles/.pyenv/versions/3.7.9/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_labels = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f9a20",
   "metadata": {},
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5eb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe2ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a1503",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd04e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel\n",
    "\n",
    "class CustomBert(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        config.output_hidden_states = True\n",
    "        super(CustomBert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        n_weights = config.num_hidden_layers + 1\n",
    "        weights_init = torch.zeros(n_weights).float()\n",
    "        weights_init.data[:-1] = -3\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    "\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        hidden_layers = outputs[2]\n",
    "\n",
    "        cls_outputs = torch.stack(\n",
    "            [self.dropout(layer[:, 0, :]) for layer in hidden_layers], dim=2\n",
    "        )\n",
    "        cls_output = (torch.softmax(self.layer_weights, dim=0) * cls_outputs).sum(-1)\n",
    "\n",
    "        # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
    "        logits = torch.mean(\n",
    "            torch.stack(\n",
    "                [self.classifier(self.high_dropout(cls_output)) for _ in range(5)],\n",
    "                dim=0,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        outputs = logits\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99166a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46882a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not SequenceClassifierOutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38/4101616258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                            attention_mask=attention_mask)\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1121\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not SequenceClassifierOutput"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "models = []\n",
    "\n",
    "for fold, (train_dataset_ids, val_dataset_ids) in enumerate(kfold.split(dataset)):\n",
    "    ## set dataset and dataloader for train\n",
    "    batch_size = 16\n",
    "    \n",
    "    train_subsampler = SubsetRandomSampler(train_dataset_ids)\n",
    "    val_subsampler = SubsetRandomSampler(val_dataset_ids)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset,\n",
    "                                  sampler=train_subsampler,\n",
    "                                  batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(dataset,\n",
    "                                sampler=val_subsampler,\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "    # set pretrained model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CustomBert.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.to(device)\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "    # set learning rate scheduler\n",
    "    epochs = 1\n",
    "    total_step = len(train_dataset_ids) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_step\n",
    "    )\n",
    "\n",
    "    def get_accuracy(preds, labels):\n",
    "        preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(preds_flat == labels_flat) / len(preds_flat)\n",
    "\n",
    "    # fine-tuning model\n",
    "\n",
    "    creterion = nn.CrossEntropyLoss()\n",
    "    current_val_loss = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0.0\n",
    "        total_val_loss = 0.0\n",
    "        total_val_accuracy = 0.0\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader, 1):\n",
    "            input_ids, attention_mask, labels = tuple(el.to(device) for el in batch)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(input_ids,\n",
    "                           token_type_ids=None,\n",
    "                           attention_mask=attention_mask)\n",
    "\n",
    "            loss = creterion(output, labels)\n",
    "            total_train_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f'Train loss: {total_train_loss / len(train_dataloader)}')\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, labels = tuple(el.to(device) for el in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_ids,\n",
    "                               token_type_ids=None,\n",
    "                               attention_mask=attention_mask)\n",
    "\n",
    "                loss = creterion(output, labels)\n",
    "                total_val_loss += loss\n",
    "\n",
    "\n",
    "            logits = output.detach().cpu().numpy()\n",
    "            label_ids = labels.detach().cpu().numpy()\n",
    "\n",
    "            total_val_accuracy += get_accuracy(logits, label_ids)\n",
    "\n",
    "        val_loss = total_val_loss / len(val_dataloader)\n",
    "        print(f'Validation loss: {val_loss}')\n",
    "        print(f'Validation accuracy: {total_val_accuracy / len(val_dataloader)}')\n",
    "\n",
    "        if epoch == 0:\n",
    "            current_val_loss = val_loss\n",
    "        else:\n",
    "            if current_val_loss <= val_loss:\n",
    "                print(f'Early stop: {epoch} epoch')\n",
    "                break\n",
    "                \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0da237",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "479f8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00721606",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks = encode_sentences(test_sentences, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0e9184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.tensor(np.ones(len(test_input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "806bc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8422ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_ids, attention_mask, labels = tuple(el.to(device) for el in batch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        models_logits = []\n",
    "        \n",
    "        for model in models:\n",
    "            output = model(input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           token_type_ids=None)\n",
    "\n",
    "            logits = output.detach().cpu().numpy()\n",
    "            models_logits.append(logits)\n",
    "        \n",
    "        sum_logits = reduce(lambda x,y: x + y, models_logits)\n",
    "        pred_flatten = np.argmax(sum_logits, axis=1).flatten()\n",
    "\n",
    "    predictions.extend(pred_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731856f",
   "metadata": {},
   "source": [
    "# calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dd08de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4781d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d21a9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8504443763407907"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_df[correct_df['target'].values == predictions].shape[0] / correct_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
